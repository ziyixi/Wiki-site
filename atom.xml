<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ziyi Xi&#39;s Wiki</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="wiki.ziyixi.science/"/>
  <updated>2019-07-16T15:10:24.465Z</updated>
  <id>wiki.ziyixi.science/</id>
  
  <author>
    <name>Ziyi Xi</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Files in ICER and Stampede2</title>
    <link href="wiki.ziyixi.science/wiki/files-in-hpcc/"/>
    <id>wiki.ziyixi.science/wiki/files-in-hpcc/</id>
    <published>2019-07-16T14:17:46.000Z</published>
    <updated>2019-07-16T15:10:24.465Z</updated>
    
    <content type="html"><![CDATA[<h2 id="overview">Overview</h2><p>Managing files in ICER and STAMPEDE2 is a important and I am supposed to find a way to place my files in order. That the reason why I write this wiki.</p><h2 id="the-summary-of-the-storage-space">The summary of the storage space</h2><p>In ICER, we have these four &quot;disks&quot;: (directly copied) <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Home Directory:</span><br><span class="line">---------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">/mnt/home/xiziyi                Quota          Used           Free           Files Quota    Files Used     Files Free</span><br><span class="line">                                1024G          251G           773G           1048576        988008         60568</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Research Groups:                Space          Space          Space          Files          Files          Files</span><br><span class="line">                                Quota          Used           Available      Quota          Used           Available</span><br><span class="line">------------------------------------------------------------------------------------------------------------------</span><br><span class="line">seismolab2                      16384G         10797G         5587G          26214400       24725040       1489360</span><br><span class="line"></span><br><span class="line">Temporary Filesystems:</span><br><span class="line">---------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">/mnt/ls15 (legacy scratch)      Inodes Used     Quota           Free</span><br><span class="line">                                115170          1000000         884830</span><br><span class="line">/mnt/scratch (/mnt/gs18)        Space Quota    Space Used     Space Free     Filess Quota   Files Used     Files Free</span><br><span class="line">                                51200G         340G           50860G         1048576        71699          976877</span><br></pre></td></tr></table></figure></p><p>And in stampede2, we have: <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--------------------- Project balances <span class="keyword">for</span> user tg851791 ----------------------</span><br><span class="line">| Name           Avail SUs     Expires | Name           Avail SUs     Expires |</span><br><span class="line">| TG-EAR140030       31763  2019-09-30 | TG-EAR130011       87905  2019-09-30 |</span><br><span class="line">------------------------ Disk quotas <span class="keyword">for</span> user tg851791 ------------------------</span><br><span class="line">| Disk         Usage (GB)     Limit    %Used   File Usage       Limit   %Used |</span><br><span class="line">| /home1              2.0      10.0    19.52        46696      200000   23.35 |</span><br><span class="line">| /work             807.4    1024.0    78.85      2742645     3000000   91.42 |</span><br><span class="line">| /scratch        23904.2       0.0     0.00     11820127           0    0.00 |</span><br><span class="line">-------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure></p><h2 id="plan">Plan</h2><p>For the research purpose, we have the following data: 1. the models, which are used to run in Specfem and for visulization. (~50 GB) 2. the data, we should keep the raw data and the processed data. (raw data: ~1 TB) 3. the sync result. Now I have these different types of sync: + 484 events for the hybrid model. (each iteration takes the 0.5 TB space) + 30 events for validation models. (total ~100 GB space each iteration) + several events for the cmt correcction. (~200 events for each iteration. 8x space than sync, so about 1.6T)</p><p>Assume we will run 20 iterations, then the total space will be: 1. The models, 50GB. 2. The data, 1TB. 3. The sync, since we will use ~200 events in each iteration, the total will be 4 TB. 4. The validation, since we will do that in each 5 iterations, the total will be 6.4 TB. 5. Kernels and Line search? COnsider them in the future.</p><p>So we will need about 12 TB space or more. So we should store any of us data in ICER's research directory and compress them accordingly. (use asdf)</p><p>As for the stampede2, we have only ~1T space. This is good for placing all the working directories. (only the structure of running specfem, and we can place the output and DATABASE_MPI in the scratch directory)</p><h2 id="the-data-structure.">The data structure.</h2><h3 id="icer">ICER</h3><ul><li>/mnt/home/xiziyi<ul><li>anaconda</li><li>bin</li><li>data</li><li>package</li><li>script</li><li>temp</li><li>test</li></ul></li><li>/mnt/research/seismolab2/japan_slab<ul><li>cmts</li><li>data</li><li>models</li><li>sync</li><li>relocation</li></ul></li></ul><p>For the data directory, we should place the directories as:</p><ul><li>raw (the seed files, should be renamed according to the gcmt id)<ul><li>fnet</li><li>cea</li><li>kma</li><li>fdsn</li></ul></li><li>processed (after having preprocessed)<ul><li>bandpass_10s_120s</li><li>bandpass_20s_120s</li><li>bandpass_40s_120s</li></ul></li></ul><p>For the sync directory, we have:</p><ul><li>hybrid<ul><li>first_iteration (sync should have the similar structure with data)</li><li>...</li></ul></li><li>validation<ul><li>EARA2014 (have the same structue with the hybrid)</li><li>FWEA18</li><li>...</li></ul></li></ul><p>For the relocation directory, we have:</p><ul><li>depth (as we may have other types of relocation)<ul><li>frist_relocation_for_xxx_iteration. (asdf files are named according to there depth, also ln the 0 depth to the sync)</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Managing files in ICER and STAMPEDE2 is a important and I am supposed to find a way to place my files in 
      
    
    </summary>
    
      <category term="hpcc" scheme="wiki.ziyixi.science/categories/hpcc/"/>
    
    
      <category term="stampede2,icer" scheme="wiki.ziyixi.science/tags/stampede2-icer/"/>
    
  </entry>
  
  <entry>
    <title>汽车购买</title>
    <link href="wiki.ziyixi.science/wiki/buy-car/"/>
    <id>wiki.ziyixi.science/wiki/buy-car/</id>
    <published>2019-06-16T14:35:45.000Z</published>
    <updated>2019-06-18T17:03:50.959Z</updated>
    
    <content type="html"><![CDATA[<h2 id="买车网站">买车网站</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;买车网站&quot;&gt;买车网站&lt;/h2&gt;

      
    
    </summary>
    
      <category term="life" scheme="wiki.ziyixi.science/categories/life/"/>
    
    
      <category term="cars" scheme="wiki.ziyixi.science/tags/cars/"/>
    
  </entry>
  
  <entry>
    <title>lasif_specfem</title>
    <link href="wiki.ziyixi.science/wiki/lasif-specfem/"/>
    <id>wiki.ziyixi.science/wiki/lasif-specfem/</id>
    <published>2019-06-14T14:46:24.000Z</published>
    <updated>2019-06-18T17:03:50.948Z</updated>
    
    <content type="html"><![CDATA[<h2 id="overview">Overview</h2><p>I'm planning to build a package named LASIF_Specfem. This package aims to create a command line tool to manage the usage of Specfem-globe. As we know that Specfem is kind of complex, and rewrite it to the structure of what a modern software should look like is difficult and complex. But anyway, we can write a python interface to it. According to <a href="https://github.com/dirkphilip/LASIF_2.0" rel="external nofollow noopener noreferrer" target="_blank">LASIF_2.0</a>, we can use directory structures to manage our data, synthetics and more.</p><p>There have already been some tools, but the problem is that these tools have some default setting which instructs you each steps. Since the scientific research is really flexble, such a restriction is not tolerable. So I'm planning to use &quot;plugins&quot; to solve this problem. The package LASIF_Specfem will only contain prototypes and set up the directory structure, and users can implement their own plugins following some interfaces.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;I&#39;m planning to build a package named LASIF_Specfem. This package aims to create a command line tool to m
      
    
    </summary>
    
      <category term="FWI" scheme="wiki.ziyixi.science/categories/FWI/"/>
    
    
      <category term="FWI" scheme="wiki.ziyixi.science/tags/FWI/"/>
    
  </entry>
  
  <entry>
    <title>correct_cea_orientation</title>
    <link href="wiki.ziyixi.science/wiki/correct-cea-orientation/"/>
    <id>wiki.ziyixi.science/wiki/correct-cea-orientation/</id>
    <published>2019-06-13T21:00:07.000Z</published>
    <updated>2019-06-13T21:53:00.326Z</updated>
    
    <content type="html"><![CDATA[<h2 id="overview">Overview</h2><p>The cea data has mis-orientated before 09/2013. We have the <a href="https://wiki.ziyixi.science/static/info/cmpaz_segment.txt">document</a> of how these stations are mis-orientated. (From Prof. Kai Tao and by Prof. Fenglin Niu) Dr. Chen has some data that have been processed before. So I'd like to compare the cmpaz of her processed data and the document mentioned above.</p><h2 id="result">Result</h2><p>The data from the document has the form</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#NET|STA|NO.EVENT|MEAN|STD|MEDIAN|MAD|STARTTIME|ENDTIME</span><br></pre></td></tr></table></figure><h3 id="ah.bas">AH.BAS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|BAS|130|8.46|10.14|10.23|4.50|2008-03-11T14:37:00Z|2010-04-11T09:40:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = 1.000000e+01</p><h3 id="ah.beb">AH.BEB</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|BEB|113|-4.82|20.58|-7.31|8.67|2007-10-02T03:43:00Z|2011-01-13T16:16:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = -7.000000e+00</p><h3 id="ah.dyn">AH.DYN</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|DYN|101|66.71|6.26|66.86|3.83|2007-08-27T17:11:00Z|2008-11-03T19:21:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = 6.500000e+01</p><h3 id="ah.fzl">AH.FZL</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#NET=AH,STA=FZL,MINCC=0.80,XYFILE=AH.FZL.XY</span><br><span class="line">#NET|STA|NO.EVENT|MEAN|STD|MEDIAN|MAD|STARTTIME|ENDTIME</span><br><span class="line">AH|FZL|3|-39.87|38.49|-60.75|3.94|2007-08-08T17:04:00Z|2007-08-15T20:22:00Z</span><br><span class="line">AH|FZL|18|-20.44|29.88|-30.98|16.20|2007-09-12T11:10:00Z|2008-03-26T20:06:00Z</span><br><span class="line">AH|FZL|3|3.09|87.01|14.27|103.34|2008-04-02T14:36:00Z|2008-04-10T04:29:00Z</span><br><span class="line">AH|FZL|1|3.69|NA|3.69|0.00|2008-04-29T19:10:00Z|2008-04-29T19:10:00Z</span><br><span class="line">AH|FZL|327|3.04|11.37|1.71|7.47|2008-05-02T01:33:00Z|2013-09-01T11:52:00Z</span><br><span class="line">AH|FZL|0|NA|NA|NA|NA|NA|2013-09-01T11:52:00Z</span><br><span class="line">AH|FZL||||||2013-09-01T11:52:00Z|NULL</span><br></pre></td></tr></table></figure><p>cmpaz = -1.000000e+00</p><p>Here we don't have the data of the for the event 200804161919A.</p><h3 id="ah.hbe">AH.HBE</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|HBE|64|13.63|5.46|13.70|3.91|2007-08-01T17:08:00Z|2008-06-10T04:13:00Z</span><br></pre></td></tr></table></figure><h3 id="ah.hef">AH.HEF</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|HEF|58|-9.22|5.11|-9.29|3.71|2007-10-31T13:44:00Z|2010-02-01T22:28:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = -9.000000e+00</p><h3 id="ah.hsh">AH.HSH</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|HSH|108|-183.73|12.04|-180.53|5.63|2007-09-12T23:49:00Z|2010-05-27T17:14:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = -1.790000e+02</p><h3 id="ah.hus">AH.HUS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|HUS|59|-4.29|4.56|-4.26|2.56|2007-08-01T17:08:00Z|2008-07-06T01:00:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = 0.000000e+00</p><h3 id="ah.jza">AH.JZA</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH|JZA|96|0.13|16.51|2.94|9.54|2007-08-08T17:04:00Z|2010-03-05T16:07:00Z</span><br></pre></td></tr></table></figure><p>cmpaz = 1.000000e+00</p><h2 id="conclusion">Conclusion</h2><p>It seems the mis-orientation data that Dr. Chen has used is slightly different from Dr. Tao has used. But they are similar to each other, only several degrees different.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;The cea data has mis-orientated before 09/2013. We have the &lt;a href=&quot;https://wiki.ziyixi.science/static/i
      
    
    </summary>
    
      <category term="Research note" scheme="wiki.ziyixi.science/categories/Research-note/"/>
    
    
      <category term="cea" scheme="wiki.ziyixi.science/tags/cea/"/>
    
  </entry>
  
  <entry>
    <title>SeisScript</title>
    <link href="wiki.ziyixi.science/wiki/SeisScript/"/>
    <id>wiki.ziyixi.science/wiki/SeisScript/</id>
    <published>2019-06-11T21:07:03.000Z</published>
    <updated>2019-06-13T20:15:27.967Z</updated>
    
    <content type="html"><![CDATA[<h2 id="overview">Overview</h2><p>Recently I have collected some of my research scripts into a package (or just a directory) named <a href="https://github.com/ziyixi/SeisScripts" rel="external nofollow noopener noreferrer" target="_blank">SeisScript</a>. This package is very useful for the need of full waveform inversion in the study of seismology. Here I'd like to introduce different parts.</p><h2 id="specfem_helper.jl">specfem_helper.jl</h2><p>At the moment, this package contains two different usable programs. (and more usable functions!) They are all inside the src/program subdirectory. Before using them, we may have to enter the <code>fortran</code> directory to run <code>julia compile.jl</code> to compile two fortran files into the dynamic library so that we can use <code>ccall</code> to call them. (I can write them in pure Julia, but I'm pretty lazy.) Also we have to edit <code>setting/constants.jl</code> to edit <code>ANGULAR_WIDTH_XI_IN_DEGREES_VAL</code>, <code>ANGULAR_WIDTH_ETA_IN_DEGREES_VAL</code>, <code>NEX_XI_VAL</code> and <code>NEX_ETA_VAL</code>.</p><p>The first program is named as <code>xsem_interp_mesh2.jl</code>, direcctly adapted from <a href="https://github.com/taotaokai/sem_utils/blob/master/src/program/xsem_interp_mesh2.f90" rel="external nofollow noopener noreferrer" target="_blank">Tao Kai's code</a>. But I have used some packages directly from Julia which makes the code more neat and more beautiful. According to my test, this program will have the same result with Tao's code, but three time slower. (That's reasonable, since Julia seems to be slower than Fortran, but I'm planning to precompile some parts to make it faster.)</p><p>The second program is named as <code>get_cross_section_data.jl</code>. This program is mainly used to calculated the point values along a specific profile of the GLL model. Previously we have a <a href="https://github.com/geokid/specfem3D_visualization/tree/master/create_slice_xyz" rel="external nofollow noopener noreferrer" target="_blank">script</a> which is designed to find the nearest points along the interface of the profile. This method is somehow not accurate. So I'm using the interpolation to calculate the values. Comparing with the previous code, this program runs faster and uses less computing resources.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Recently I have collected some of my research scripts into a package (or just a directory) named &lt;a href=
      
    
    </summary>
    
      <category term="FWI" scheme="wiki.ziyixi.science/categories/FWI/"/>
    
    
      <category term="FWI" scheme="wiki.ziyixi.science/tags/FWI/"/>
    
  </entry>
  
  <entry>
    <title>Comparision of different filters in preprocessing data</title>
    <link href="wiki.ziyixi.science/wiki/taper/"/>
    <id>wiki.ziyixi.science/wiki/taper/</id>
    <published>2019-06-11T21:07:03.000Z</published>
    <updated>2019-06-13T20:17:44.196Z</updated>
    
    <content type="html"><![CDATA[<h2 id="filters">Filters</h2><p>In the seismic research, we have to preprocess the data. Specially in the field of FWI, we may have to compare the synthetics and the data, and then calculate the misfit function. Here I compare two different way to get our desired frequency range.</p><h3 id="bandpass">Bandpass</h3><p>The data we have the <a href="https://wiki.ziyixi.science/static/data/AH.DYN.BHZ.trim">data</a> and the <a href="https://wiki.ziyixi.science/static/data/AH.DYN.BHZ.pz">PZ file</a>. And then we can use SAC to preprocess it:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r AH.DYN.BHZ.trim</span><br><span class="line">rmean; rtr; taper;</span><br><span class="line">trans from polezero s ./AH.DYN.BHZ.pz to none freq 0.004 0.005 1 1.2</span><br><span class="line">bp n 2 p 2 c 0.01 0.0025</span><br></pre></td></tr></table></figure><p>So here we will get the processed data with the frequency range of 40s to 100s.</p><h3 id="taper-in-the-frequency-domain">Taper in the frequency domain</h3><p>We can also directly get the final result as:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r AH.DYN.BHZ.trim</span><br><span class="line">rmean; rtr; taper;</span><br><span class="line">trans from polezero s ./AH.DYN.BHZ.pz to none freq 0.008 0.01 0.025 0.03</span><br></pre></td></tr></table></figure><h2 id="result">Result</h2><p>We can compare the result as: <img src="https://wiki.ziyixi.science/static/figures/compare.png"></p><p>As we can see, the black line represents &quot;taper from 0.004HZ to 0.005HZ&quot; and then removing the instrumental response, while the blue line represents &quot;taper from 0.01HZ to 0.0025HZ&quot; and then removing the instrumental response. And the red line represnets apply a bandpass filter from 0.01HZ to 0.0025HZ to the black line.</p><p>In FWI research, we want to keep as much as energy in our desired frequency band. So it seems the blue has not losed the energy, which is better then the red line. Also the blue line has almost the same amount of enery with the red line. However, there is an abrupt jump of the blue line, which may cause some artifact.</p><p><img src="https://wiki.ziyixi.science/static/figures/waveform_compare.png"></p><p>Look at part from 800s to 1000s. It seems the &quot;phases&quot; in the black line are the artifact, which may cause some problem for the comparision of the surface wave. Anyway, the behavior of sync and data outside our desired frequency range is somehow different.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;filters&quot;&gt;Filters&lt;/h2&gt;
&lt;p&gt;In the seismic research, we have to preprocess the data. Specially in the field of FWI, we may have to comp
      
    
    </summary>
    
      <category term="DSP" scheme="wiki.ziyixi.science/categories/DSP/"/>
    
    
      <category term="filter" scheme="wiki.ziyixi.science/tags/filter/"/>
    
  </entry>
  
  <entry>
    <title>未来职业规划</title>
    <link href="wiki.ziyixi.science/wiki/index/"/>
    <id>wiki.ziyixi.science/wiki/index/</id>
    <published>2019-06-11T18:49:41.000Z</published>
    <updated>2019-06-23T17:49:20.380Z</updated>
    
    <content type="html"><![CDATA[<p>谈到我自己的未来职业规划，我这里有一些比较初步的想法。</p><p>首先的一个关键问题在于我今后应该从事学术界的工作还是工业界的工作，这一点非常重要。从我本科时候的经历来看，要想在每一个人生阶段结束的时候达到一个更好的位置，就应该提早做准备。（譬如我自己出国这件事情其实是在大三下学期才开始正式开始准备的，这一点无疑成为我申请时候的劣势）此外我们还应该明白在每一阶段自己的核心竞争力是什么。在 PhD 阶段，我个人认为还是要着眼于科研。第一点在于做了些什么东西，即所做工作的数量。内行毕竟是少数，别人评价自己都要从一些标准的评价手段来看。（主要是发了些什么文章，在什么样的期刊上发了文章。）其次是所做的领域。（是否代表了学科的发展方向，是否具有真正的价值。）最后是所做工作的延伸性。（如何为自己创造更多的机会。）</p><p>回顾我现在所做的事情，大约在今年结束之前能把模型计算出来，在明年暑假之前文章应该可以发表。我自己所做的另一个算法方面的工作，我预计是能发一篇比较小的 paper。所以在前两年（或者三年），我应该能有两篇一作文章到手。再加上蹭师兄的两篇二作文章，我在前两年就会有四篇文章。从文章数目来看，我觉得似乎还是可以的。但是考虑到自己学校的问题，MSU 毕竟不能为我找工作提供助力。如果我想在国内找工作的话，所能凭借的有如下几点：教育背景：科大毕业，海外 PhD。学科背景：理科专业，cs dual，HPC 相关。我个人觉得这些条件应该能让我达到各大企业的基本入门要求，所以从这一点来看找工业界的工作还是有一些机会的。</p><p>如果我要从事学术界的工作的话，首先一点在于学术界的内卷现象。虽然说如果自己有比较好的 publication 的话，还是比较有希望在 PhD 毕业的时候找到一个比较好的博后位置，以至于再走教职的常规路线。理论上讲我是能走这条路的，而且走这条路的各个时期所要做的事情都是可以预期的。可是走这条路的一个大问题在于竞争激烈。不用脑子想我也知道业界待遇和职位数额要远远大于学术界。从我的观点来看，不转行的一部分在于确实拥有着远大的学术理想。但是更多的我觉得是不能跳出自己的舒适区。而从我个人发展的角度来看，我或者从我个人的兴趣来看，我其实还是比较喜欢做一些基础性的 coding 工作的，而且经过一直以来对学术界和业界的对比来看，我觉得业界还是更能实现我个人价值的地方。</p><p>如果从事业界工作，什么能力是我需要具备的？</p><ol type="1"><li><p>基础知识。cs 本科很多东西我都是水水而过，我个人觉得还需要加强。此外现在做 cs 相关工作，还有很多知识需要加以补充，具体而言，我觉得有如下事情需要去做：</p><ol type="1"><li>离散数学。Rosen_Discrete_Mathematics_and_Its_Applications_7th_Edition</li><li>算法。 算法导论</li><li>C++。cpp 是编程的基本功，不是学学 py 或者 Julia 能够取代的。而且自然我应该重读一下 C++ primer。</li><li>操作系统。这一科我建议直接阅读 computer systems 一书。我觉得可以和计算机系统一课合并。</li><li>数据库。 直接学习 SQL 学习指南这一动物书。</li><li>计算机网络。 这一科其实我不是非常喜欢，暂且扔掉。</li><li>编译原理。 学习 engineering a compiler 一书。</li><li>综上所述，我一共需要阅读六本书。因为我之前有 cs 的基础，所以除了算法导论一书外我觉得其余的书都可以在一个月内读完。算法导论需要阅读两到三个月之间。</li></ol></li><li>进阶知识。我希望从事的方向是偏向机器学习的高性能计算方面的工作，比如设计 GPU 算法之类的活。我自认为我在这一方面是比较有学习优势的。这就要求我在机器学习和高性能计算方面两手抓。<ol type="1"><li>GPU 基础知识。我需要知道如何使用 GPU，也需要知道其底层的原理。甚至对于 tpu 的相关知识，我也应该加以学习。我觉得可以阅读 Programming massively parallel processors: A hands-on approach 一书。</li><li>CUDA 编程。我希望熟练掌握 c++，py 和 Julia 的 CUDA 编程。暂且阅读 CUDA C programming 一书。</li><li>学习“系统研究背景：操作系统、移动计算、边缘计算、分布式系统、硬件等”。这个日后详谈。</li><li>学习数电与 FPGA。</li></ol></li></ol><p>Anyway，我需要每天确保一定的学习时间，以便在明年暑假实习的时候达到应有的 cs 科班水平。此外应当关注科大的微软亚洲研究院的教授，以便参加 MSRA 的暑假实习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;谈到我自己的未来职业规划，我这里有一些比较初步的想法。&lt;/p&gt;
&lt;p&gt;首先的一个关键问题在于我今后应该从事学术界的工作还是工业界的工作，这一点非常重要。从我本科时候的经历来看，要想在每一个人生阶段结束的时候达到一个更好的位置，就应该提早做准备。（譬如我自己出国这件事情其实是
      
    
    </summary>
    
      <category term="所思所想" scheme="wiki.ziyixi.science/categories/%E6%89%80%E6%80%9D%E6%89%80%E6%83%B3/"/>
    
    
  </entry>
  
</feed>
